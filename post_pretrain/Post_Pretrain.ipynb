{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1f95LnlhFI6R17cIcJASiE98AfGy3uuCr",
      "authorship_tag": "ABX9TyOz3l/AtqRV2uHGzuzw8w/w",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jx-dohwan/BERT-FP_MRS/blob/main/post_pretrain/Post_Pretrain.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Post-training"
      ],
      "metadata": {
        "id": "cVenUKAHi5-z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 라이브러리 설치"
      ],
      "metadata": {
        "id": "jH75PgrgjBGJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gqX3WxLyi1H3",
        "outputId": "ce798a47-9f68-4c58-d24e-28ee9e144b98"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.8/dist-packages (1.13.1+cu116)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch) (4.4.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers==4.25.1 in /usr/local/lib/python3.8/dist-packages (4.25.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers==4.25.1) (23.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.10.0 in /usr/local/lib/python3.8/dist-packages (from transformers==4.25.1) (0.12.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers==4.25.1) (1.21.6)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers==4.25.1) (3.9.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers==4.25.1) (2022.6.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers==4.25.1) (6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers==4.25.1) (2.25.1)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.8/dist-packages (from transformers==4.25.1) (0.13.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers==4.25.1) (4.64.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers==4.25.1) (4.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers==4.25.1) (2022.12.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers==4.25.1) (2.10)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers==4.25.1) (4.0.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers==4.25.1) (1.24.3)\n"
          ]
        }
      ],
      "source": [
        "!pip install torch\n",
        "!pip install transformers==4.25.1"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y21vmEjKjMyc",
        "outputId": "2f3c62f1-942e-4ca1-ae5f-1061f35ed4c4"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NVIDIA-SMI has failed because it couldn't communicate with the NVIDIA driver. Make sure that the latest NVIDIA driver is installed and running.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 데이터 다운로드"
      ],
      "metadata": {
        "id": "reklAI1YjXjy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 스마일 스타일 데이터세트(for 대화 및 스타일 트랜스퍼)"
      ],
      "metadata": {
        "id": "sVoUGEDzjZvB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/smilegate-ai/korean_smile_style_dataset\n",
        "# https://corpus.korean.go.kr/\n",
        "# https://aihub.or.kr/aihub-data/natural-language/about"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "22U2-AHDjU_y",
        "outputId": "52b2fa35-e418-42cf-b1ba-5397cda83533"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'korean_smile_style_dataset' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv('/content/korean_smile_style_dataset/smilestyle_dataset.tsv', sep='\\t')\n",
        "df.to_csv('./korean_smile_style_dataset/smile.csv', index=False)"
      ],
      "metadata": {
        "id": "eXSSXMFxjunK"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!head -3 './korean_smile_style_dataset/smile.csv'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u0v7T4wxkJwc",
        "outputId": "64a16dbd-b14a-4fc2-93e4-17d1319b856a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "formal,informal,android,azae,chat,choding,emoticon,enfp,gentle,halbae,halmae,joongding,king,naruto,seonbi,sosim,translator\n",
            "안녕하세요. 저는 고양이 6마리 키워요.,안녕! 나는 고양이 6마리 키워.,휴먼. 반갑다. 안드로이드는. 고양이. 6마리. 소유중.,아이고 안녕하십니까~ 나는 그냥 고양이 6마리 키우고 있는 사람이여,하잉ㅋㅋ 나 떼걸룩 6마리 키운다!,ㅎㅇ 나 주인님 6마리 모심 ㅋㅋ,안녕!! >< 나는 고양이😺를 ➏ 마리 키우고있어!! 0_0,안녕안녕~! 나 고양이 6마리나 키운다? 완전 대박이징~,\"안녕하십니까,, 저는 고양이 6마리 키웁니다.\",안녕하신가~... 난 지금 고양이를 6마리 키우고 있다네,하유 시벌것 괭이놈 6마리 키우는데 힘들어 죽겟네,안녕하냐 ㅡㅡ 나 씹냥이 6마리나 키운다 하;,반갑소. 짐은 고양이를 6마리나 키우오.,안녕하냐니깐! 난 고양이를 6마리 키우고있다니깐!,안녕하시오! 소인은 고양이를 6마리 키우고 있소!,안녕… 난 고양이 6마리 키워 ㅠㅠ,반가운. 나는 6마리의 고양이를 소지하고 있다.\n",
            "고양이를 6마리나요? 키우는거 안 힘드세요?,고양이를 6마리나? 키우는거 안 힘들어?,고양이. 6마리. 양육. 번거로운가.,아니 무슨 고양이를 6마리나? 거 키우는 거 안 힘든가?,엥? 6마리나? 안힘듬?ㅋㅋㅋㅋ,6마리? 에바아니냐 안 힘듦?,고양이를 6마리나?!! w(ﾟДﾟ)w 키우는거 안 힘듬?? (⊙_⊙;),고양이를 6마리나? 완전 대박~ 키우는 거 안 힘들어?!,\"고양이를 6마리나 키우십니까? 안 힘드신지,,\",고양이를 6마리나? 키우는거 힘들지 않는가?,니기럴 털만 날리는 거 키우기 안 힘들데?,아니 고양이를 6마리나? 안힘드냐?,고양이를 6마리나? 키우는게 수고스럽진 않소?,고양이를 6마리나? 키우는거 힘들지 않냐니깐?,고양이를 6마리나 키우고 있는 것이오? 힘들지 않소?,고양이..6마리나? ㅠ 키우는건 혹시 안힘들어..?,6마리의 고양이? 당신은 그들로부터 지치지 않습니까?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 데이터 가공하기"
      ],
      "metadata": {
        "id": "ZkmRR95TkZWL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "\n",
        "data_path = './korean_smile_style_dataset/smile.csv'\n",
        "f = open(data_path, 'r')\n",
        "rdr = csv.reader(f)\n",
        "\n",
        "for line in rdr:\n",
        "    print(line)\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BpVJsdF6kOya",
        "outputId": "04df9196-d9e9-4090-b956-176bbcad8b57"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['formal', 'informal', 'android', 'azae', 'chat', 'choding', 'emoticon', 'enfp', 'gentle', 'halbae', 'halmae', 'joongding', 'king', 'naruto', 'seonbi', 'sosim', 'translator']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 저장\n",
        "def split(session):\n",
        "    final_data = []\n",
        "    split_session = []\n",
        "    for line in session:\n",
        "        split_session.append(line)\n",
        "        final_data.append(split_session[:])\n",
        "    return final_data\n",
        "\n",
        "f = open(data_path, 'r')\n",
        "rdr = csv.reader(f)\n",
        "\n",
        "\"\"\" 세션 데이터 저장할 것\"\"\"\n",
        "session_dataset = []\n",
        "session = []\n",
        "\n",
        "\"\"\" 실제 데이터 저장 방식 \"\"\"\n",
        "for i, line in enumerate(rdr):\n",
        "    if i == 0:\n",
        "        header = line\n",
        "    else:\n",
        "        utt = line[0] #formal\n",
        "        if utt.strip() != '':\n",
        "            session.append(utt)\n",
        "        else:\n",
        "            \"\"\" 세션 데이터 저장 \"\"\"\n",
        "            session_dataset.append(session)\n",
        "            session = []\n",
        "\"\"\" 마지막 세션 저장 \"\"\"\n",
        "session_dataset.append(session)\n",
        "f.close()"
      ],
      "metadata": {
        "id": "oqqZYKXalM_D"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "session_dataset[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MvmiiWL-mRxa",
        "outputId": "64d3dd27-707e-4cb0-fa0e-39e5d37cfbdf"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['안녕하세요. 저는 고양이 6마리 키워요.',\n",
              " '고양이를 6마리나요? 키우는거 안 힘드세요?',\n",
              " '제가 워낙 고양이를 좋아해서 크게 힘들진 않아요.',\n",
              " '가장 나이가 많은 고양이가 어떻게 돼요?',\n",
              " '여섯 살입니다. 갈색 고양이에요.',\n",
              " '그럼 가장 어린 고양이가 어떻게 돼요?',\n",
              " '한 살입니다. 작년에 분양 받았어요.',\n",
              " '그럼 고양이들끼리 안 싸우나요?',\n",
              " '저희 일곱은 다같이 한 가족입니다. 싸우는 일은 없어요.']"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(session_dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SSKUlUoZmUAC",
        "outputId": "9d15ca77-532f-46e2-e93e-746bbccbe933"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "236"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 모델을 학습하기 위한 loss "
      ],
      "metadata": {
        "id": "hHYDlQ8Omx7W"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UPrhA7rZmiRR"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## MLM을 위한 입력"
      ],
      "metadata": {
        "id": "c-7PP6JUnrXd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " from transformers import AutoTokenizer\n",
        " tokenizer = AutoTokenizer.from_pretrained('klue/roberta-base')"
      ],
      "metadata": {
        "id": "X8BL0KIAnstl"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.special_tokens_map_extended"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TXlRX0T-sZX6",
        "outputId": "7e54000a-f950-417c-8fff-37be8433db1d"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'bos_token': '[CLS]',\n",
              " 'eos_token': '[SEP]',\n",
              " 'unk_token': '[UNK]',\n",
              " 'sep_token': '[SEP]',\n",
              " 'pad_token': '[PAD]',\n",
              " 'cls_token': '[CLS]',\n",
              " 'mask_token': '[MASK]'}"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.eos_token, tokenizer.sep_token, tokenizer.eos_token_id, tokenizer.sep_token_id"
      ],
      "metadata": {
        "id": "A2l8WIxwsgBt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d2c1d84-a02d-489c-b72e-e29f572bdbe9"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('[SEP]', '[SEP]', 2, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "논문 입력 형태 [CLS] u1 [EOU] ... ut-1 [EOU] [SEP] ut [SEP]\n",
        "sep_token을 다른 토큰으로 변경하자\n",
        "-> 입력형태 : [CLS] u1 <SEP> ... ut-1 <SEP> [SEP] ut [SEP]\n",
        "\"\"\"\n",
        "\n",
        "special_tokens = {'sep_token' : '<SEP>'}\n",
        "tokenizer.add_special_tokens(special_tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cjHrpo9C-7MA",
        "outputId": "5c05a1ac-b5ce-4655-c361-e13a17de78f5"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.eos_token, tokenizer.sep_token, tokenizer.eos_token_id, tokenizer.sep_token_id"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r-9fDfasE6SD",
        "outputId": "bc959ade-e22f-4b15-fef3-6a4b8df06362"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('[SEP]', '<SEP>', 2, 32000)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.mask_token, tokenizer.mask_token_id"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gTheubcnE8_z",
        "outputId": "7ccea7ec-9b0f-4230-a21d-7d83cc36c36c"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('[MASK]', 4)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "session = session_dataset[0]\n",
        "mask_ratio = 0.15\n",
        "corrupt_tokens = []\n",
        "output_tokens = []\n",
        "\n",
        "for i, utt in enumerate(session):\n",
        "    original_token = tokenizer.encode(utt, add_special_tokens=False)\n",
        "\n",
        "    mask_num = int(len(original_token)*mask_ratio)\n",
        "    mask_positions = random.sample([x for x in range(len(original_token))], mask_num)\n",
        "    corrupt_token = []\n",
        "    for pos in range(len(original_token)):\n",
        "        if pos in mask_positions:\n",
        "            corrupt_token.append(tokenizer.mask_token_id)\n",
        "        else:\n",
        "            corrupt_token.append(original_token[pos])\n",
        "            \n",
        "    if i == len(session)-1:\n",
        "        output_tokens += original_token\n",
        "        corrupt_tokens += corrupt_token\n",
        "    else:\n",
        "        output_tokens += original_token + [tokenizer.sep_token_id]\n",
        "        corrupt_tokens += corrupt_token + [tokenizer.sep_token_id]"
      ],
      "metadata": {
        "id": "fMa1ms4LFYbC"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokenizer.decode(output_tokens))\n",
        "print('###')\n",
        "print(tokenizer.decode(corrupt_tokens))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XWf2e4hpHBPF",
        "outputId": "92b530e0-26d3-4cb7-db11-2165837269b0"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "안녕하세요. 저는 고양이 6마리 키워요. <SEP> 고양이를 6마리나요? 키우는거 안 힘드세요? <SEP> 제가 워낙 고양이를 좋아해서 크게 힘들진 않아요. <SEP> 가장 나이가 많은 고양이가 어떻게 돼요? <SEP> 여섯 살입니다. 갈색 고양이에요. <SEP> 그럼 가장 어린 고양이가 어떻게 돼요? <SEP> 한 살입니다. 작년에 분양 받았어요. <SEP> 그럼 고양이들끼리 안 싸우나요? <SEP> 저희 일곱은 다같이 한 가족입니다. 싸우는 일은 없어요.\n",
            "###\n",
            "안녕하세요. 저는 고양이 6 [MASK] 키워요. <SEP> 고양이를 6마리나요? 키우는거 안 [MASK]세요 [MASK] <SEP> 제가 워낙 고양이를 좋아해서 [MASK]게 힘들진 않 [MASK]요. <SEP> 가장 나이가 많은 고양이 [MASK] 어떻게 돼요? <SEP> 여섯 살입니다. [MASK] 고양이에요. <SEP> 그럼 가장 [MASK] 고양이가 어떻게 돼요? <SEP> [MASK] 살입니다. 작년에 분양 받았어요. <SEP> 그럼 [MASK]들끼리 안 싸우나요? <SEP> 저희 일곱은 다같이 한 가족입니다 [MASK] 싸우는 일은 없어요 [MASK]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## URC를 위한 입력 토큰"
      ],
      "metadata": {
        "id": "zJalfojJWb0f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### short session 구성"
      ],
      "metadata": {
        "id": "PoNbqAKyXbgG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "k =4 # 논문 참조 (3개는 context, 1개는 response)\n",
        "short_session_dataset = []\n",
        "for session in session_dataset:\n",
        "      for i in range(len(session)-k+1):\n",
        "          short_session_dataset.append(session[i:i+k])\n",
        "print(len(short_session_dataset))"
      ],
      "metadata": {
        "id": "XsGInLYjHMrL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "86047bbd-24e2-4277-c84f-03086455803a"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2762\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "short_session_dataset[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k0Iy-L4MXVaU",
        "outputId": "063dc5a9-bc51-4d48-ec16-aed04136d0d4"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['안녕하세요. 저는 고양이 6마리 키워요.',\n",
              " '고양이를 6마리나요? 키우는거 안 힘드세요?',\n",
              " '제가 워낙 고양이를 좋아해서 크게 힘들진 않아요.',\n",
              " '가장 나이가 많은 고양이가 어떻게 돼요?']"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### URC 입력 만들기"
      ],
      "metadata": {
        "id": "Xv4kUnBSXd7E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 모든 발화가 negativ response candidate\n",
        "import random\n",
        "\n",
        "all_utts = set()\n",
        "for session in session_dataset:\n",
        "    for utt in session:\n",
        "        all_utts.add(utt)\n",
        "all_utts = list(all_utts)\n",
        "print(len(all_utts), all_utts[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RuUwmvHKW-Lu",
        "outputId": "f004fc1e-f7b5-43de-a693-9ceead708593"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3430 잠수함이나 스노클링 도구 같이 비싼 도구 없이 어떻게 수면 아래를 감상하나요?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "session = short_session_dataset[0]\n",
        "urc_tokens = []\n",
        "context_utts = []\n",
        "for i in range(len(session)):\n",
        "    utt = session[i]    \n",
        "    original_token = tokenizer.encode(utt, add_special_tokens=False)\n",
        "    if i == len(session)-1:\n",
        "        # urc_tokens += [tokenizer.eos_token_id]\n",
        "        \"\"\" 기존 response 입력 \"\"\" # 마지막 발화\n",
        "        positive_tokens = urc_tokens + original_token \n",
        "        \"\"\" random negative respons 입력 \"\"\" # random으로 선택해서 넣어준다.\n",
        "        while True:\n",
        "            random_neg_response = random.choice(all_utts)\n",
        "            if random_neg_response not in context_utts:\n",
        "                break\n",
        "        random_neg_response_token = tokenizer.encode(random_neg_response, add_special_tokens=False)\n",
        "        random_tokens = urc_tokens + random_neg_response_token\n",
        "        \"\"\" context negative response 입력 \"\"\" #context_utts에서 랜덤으로 하나 뽑아준다.\n",
        "        context_neg_response = random.choice(context_utts)\n",
        "        context_neg_response_token = tokenizer.encode(context_neg_response, add_special_tokens=False)\n",
        "        context_neg_tokens = urc_tokens + context_neg_response_token\n",
        "    else:\n",
        "        urc_tokens += original_token + [tokenizer.sep_token_id]\n",
        "    context_utts.append(utt)"
      ],
      "metadata": {
        "id": "M3_E8aMeXt1C"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokenizer.decode(positive_tokens)) # 0\n",
        "print('#####')\n",
        "print(tokenizer.decode(random_tokens)) # 1\n",
        "print('#####')\n",
        "print(tokenizer.decode(context_neg_tokens)) # 2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dxbg58i0Y88O",
        "outputId": "67d2db6a-79db-4556-a66e-914047615a28"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "안녕하세요. 저는 고양이 6마리 키워요. <SEP> 고양이를 6마리나요? 키우는거 안 힘드세요? <SEP> 제가 워낙 고양이를 좋아해서 크게 힘들진 않아요. <SEP> 가장 나이가 많은 고양이가 어떻게 돼요?\n",
            "#####\n",
            "안녕하세요. 저는 고양이 6마리 키워요. <SEP> 고양이를 6마리나요? 키우는거 안 힘드세요? <SEP> 제가 워낙 고양이를 좋아해서 크게 힘들진 않아요. <SEP> 저는 출근하는게 너무 즐거워요.\n",
            "#####\n",
            "안녕하세요. 저는 고양이 6마리 키워요. <SEP> 고양이를 6마리나요? 키우는거 안 힘드세요? <SEP> 제가 워낙 고양이를 좋아해서 크게 힘들진 않아요. <SEP> 안녕하세요. 저는 고양이 6마리 키워요.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 데이터 로드 만들기"
      ],
      "metadata": {
        "id": "rYQDZPx3bSCF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "import random\n",
        "from torch.utils.data import Dataset\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "class post_loader(Dataset):\n",
        "    def __init__(self, data_path):\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained('klue/roberta-base')\n",
        "        special_tokens = {'sep_token': '<SEP>'}\n",
        "        self.tokenizer.add_special_tokens(special_tokens)\n",
        "\n",
        "        f = open(data_path, 'r')\n",
        "        rdr = csv.reader(f)\n",
        "\n",
        "        \"\"\" 세션 데이터 저장할 것\"\"\"\n",
        "        session_dataset = []\n",
        "        session = []\n",
        "\n",
        "        \"\"\" 실제 데이터 저장 방식 \"\"\"\n",
        "        for i, line in enumerate(rdr):\n",
        "            if i == 0:\n",
        "                header = line\n",
        "            else:\n",
        "                utt = line[0] #formal\n",
        "                if utt.strip() != '':\n",
        "                    session.append(utt)\n",
        "                else:\n",
        "                    \"\"\" 세션 데이터 저장 \"\"\"\n",
        "                    session_dataset.append(session)\n",
        "                    session = []\n",
        "        \"\"\" 마지막 세션 저장 \"\"\"\n",
        "        session_dataset.append(session)\n",
        "        f.close()\n",
        "\n",
        "        \"\"\" short session context \"\"\"\n",
        "        self.short_session_dataset = []\n",
        "        for session in session_dataset:\n",
        "              for i in range(len(session)-k+1):\n",
        "                  self.short_session_dataset.append(session[i:i+k])\n",
        "\n",
        "        \"\"\" 모든 발화 저장 \"\"\"\n",
        "        self.all_utts = set()\n",
        "        for session in session_dataset:\n",
        "            for utt in session:\n",
        "                self.all_utts.add(utt)\n",
        "        self.all_utts = list(self.all_utts)\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.short_session_dataset)\n",
        "\n",
        "    def __getitem__(self, idx): \n",
        "        session = self.short_session_dataset[idx]\n",
        "        \"\"\"MLM입력\"\"\"\n",
        "        mask_ratio = 0.15\n",
        "        self.corrupt_tokens = []\n",
        "        self.output_tokens = []\n",
        "\n",
        "        for i, utt in enumerate(session):\n",
        "            original_token = self.tokenizer.encode(utt, add_special_tokens=False)\n",
        "\n",
        "            mask_num = int(len(original_token)*mask_ratio)\n",
        "            mask_positions = random.sample([x for x in range(len(original_token))], mask_num)\n",
        "            corrupt_token = []\n",
        "            for pos in range(len(original_token)):\n",
        "                if pos in mask_positions:\n",
        "                    corrupt_token.append(self.tokenizer.mask_token_id)\n",
        "                else:\n",
        "                    corrupt_token.append(original_token[pos])\n",
        "                    \n",
        "            if i == len(session)-1:\n",
        "                self.output_tokens += original_token\n",
        "                self.corrupt_tokens += corrupt_token\n",
        "            else:\n",
        "                self.output_tokens += original_token + [self.tokenizer.sep_token_id]\n",
        "                self.corrupt_tokens += corrupt_token + [self.tokenizer.sep_token_id]\n",
        "\n",
        "\n",
        "        \"\"\" label for loss \"\"\"\n",
        "        self.corrupt_mask_positions = []\n",
        "        for pos in range(len(self.corrupt_tokens)):\n",
        "            if self.corrupt_tokens[pos] == self.tokenizer.mask_token_id:\n",
        "                self.corrupt_mask_positions.append(pos)\n",
        "\n",
        "        \"\"\" URC 입력 \"\"\"\n",
        "        urc_tokens = []\n",
        "        context_utts = []\n",
        "        for i in range(len(session)):\n",
        "            utt = session[i]    \n",
        "            original_token = self.tokenizer.encode(utt, add_special_tokens=False)\n",
        "            if i == len(session)-1:\n",
        "                urc_tokens += [self.tokenizer.eos_token_id]\n",
        "                \"\"\" 기존 response 입력 \"\"\" # 마지막 발화\n",
        "                self.positive_tokens = [self.tokenizer.cls_token_id] + urc_tokens + original_token # cls token 추가 \n",
        "                \"\"\" random negative respons 입력 \"\"\" # random으로 선택해서 넣어준다.\n",
        "                while True:\n",
        "                    random_neg_response = random.choice(self.all_utts)\n",
        "                    if random_neg_response not in context_utts:\n",
        "                        break\n",
        "                random_neg_response_token = self.tokenizer.encode(random_neg_response, add_special_tokens=False)\n",
        "                self.random_tokens = [self.tokenizer.cls_token_id] + urc_tokens + random_neg_response_token\n",
        "                \"\"\" context negative response 입력 \"\"\" #context_utts에서 랜덤으로 하나 뽑아준다.\n",
        "                context_neg_response = random.choice(context_utts)\n",
        "                context_neg_response_token = self.tokenizer.encode(context_neg_response, add_special_tokens=False)\n",
        "                self.context_neg_tokens = [self.tokenizer.cls_token_id] + urc_tokens + context_neg_response_token\n",
        "            else:\n",
        "                urc_tokens += original_token + [self.tokenizer.sep_token_id]\n",
        "            context_utts.append(utt)\n",
        "\n",
        "        return self.corrupt_tokens, self.output_tokens, self.corrupt_mask_positions, [self.positive_tokens, self.random_tokens, self.context_neg_tokens], [0,1,2]"
      ],
      "metadata": {
        "id": "ZdaOm5LXa9Ow"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_path = './korean_smile_style_dataset/smile.csv'\n",
        "post_dataset = post_loader(data_path)"
      ],
      "metadata": {
        "id": "6ndJicmMFktM"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corrupt_tokens, output_tokens, corrupt_mask_positions, urc_inputs, urc_labels = post_dataset[0]"
      ],
      "metadata": {
        "id": "KwFZTJFEG5cM"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(post_dataset.tokenizer.decode(corrupt_tokens))\n",
        "print(post_dataset.tokenizer.decode(output_tokens))\n",
        "print(corrupt_mask_positions) # 이 부분에 해당하는 loss를 계산해야함함\n",
        "print('#####')\n",
        "print(post_dataset.tokenizer.decode(urc_inputs[0]))\n",
        "print(post_dataset.tokenizer.decode(urc_inputs[1]))\n",
        "print(post_dataset.tokenizer.decode(urc_inputs[2]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OK-oeJXkIUJx",
        "outputId": "360f2c81-76a0-4c1c-c8c3-a23010841295"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "안녕하 [MASK]. 저는 고양이 6마리 키워요. <SEP> 고양이를 6마리나 [MASK]? 키우는거 안 [MASK]세요? <SEP> 제 [MASK] 워낙 고양이를 좋아해서 크게 힘들진 않아 [MASK]. <SEP> 가장 나이가 [MASK]은 고양이가 어떻게 돼요?\n",
            "안녕하세요. 저는 고양이 6마리 키워요. <SEP> 고양이를 6마리나요? 키우는거 안 힘드세요? <SEP> 제가 워낙 고양이를 좋아해서 크게 힘들진 않아요. <SEP> 가장 나이가 많은 고양이가 어떻게 돼요?\n",
            "[2, 18, 24, 29, 40, 46]\n",
            "#####\n",
            "[CLS] 안녕하세요. 저는 고양이 6마리 키워요. <SEP> 고양이를 6마리나요? 키우는거 안 힘드세요? <SEP> 제가 워낙 고양이를 좋아해서 크게 힘들진 않아요. <SEP> [SEP] 가장 나이가 많은 고양이가 어떻게 돼요?\n",
            "[CLS] 안녕하세요. 저는 고양이 6마리 키워요. <SEP> 고양이를 6마리나요? 키우는거 안 힘드세요? <SEP> 제가 워낙 고양이를 좋아해서 크게 힘들진 않아요. <SEP> [SEP] 네, 이제 유전의 기본 원리에 대해 조금 알 것 같아요.\n",
            "[CLS] 안녕하세요. 저는 고양이 6마리 키워요. <SEP> 고양이를 6마리나요? 키우는거 안 힘드세요? <SEP> 제가 워낙 고양이를 좋아해서 크게 힘들진 않아요. <SEP> [SEP] 고양이를 6마리나요? 키우는거 안 힘드세요?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 배치 처리"
      ],
      "metadata": {
        "id": "Y0lMIsNIJGf4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "import random\n",
        "from torch.utils.data import Dataset\n",
        "from transformers import AutoTokenizer\n",
        "import torch\n",
        "\n",
        "class post_loader(Dataset):\n",
        "    def __init__(self, data_path):\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained('klue/roberta-base')\n",
        "        special_tokens = {'sep_token': '<SEP>'}\n",
        "        self.tokenizer.add_special_tokens(special_tokens)\n",
        "        \n",
        "        f = open(data_path, 'r')\n",
        "        rdr = csv.reader(f)        \n",
        "        \n",
        "        \"\"\" 세션 데이터 저장할 것\"\"\"\n",
        "        session_dataset = []\n",
        "        session = []\n",
        "\n",
        "        \"\"\" 실제 데이터 저장 방식 \"\"\"\n",
        "        for i, line in enumerate(rdr):\n",
        "            if i == 0:\n",
        "                header  = line\n",
        "            else:\n",
        "                utt = line[0]\n",
        "                if utt.strip() != '':\n",
        "                    session.append(utt)\n",
        "                else:\n",
        "                    \"\"\" 세션 데이터 저장 \"\"\"\n",
        "                    session_dataset.append(session)\n",
        "                    session = []\n",
        "        \"\"\" 마지막 세션 저장 \"\"\"\n",
        "        session_dataset.append(session)\n",
        "        f.close()\n",
        "        \n",
        "        \"\"\" short session context \"\"\"\n",
        "        k = 4 # 논문에서 가장 좋았던 숫자\n",
        "        self.short_session_dataset = []\n",
        "        for session in session_dataset:    \n",
        "            for i in range(len(session)-k+1):\n",
        "                self.short_session_dataset.append(session[i:i+k])\n",
        "                \n",
        "        \"\"\" 모든 발화 저장 \"\"\"\n",
        "        self.all_utts = set()\n",
        "        for session in session_dataset:\n",
        "            for utt in session:\n",
        "                self.all_utts.add(utt)\n",
        "        self.all_utts = list(self.all_utts)\n",
        "        \n",
        "    def __len__(self): # 기본적인 구성\n",
        "        return len(self.short_session_dataset)\n",
        "    \n",
        "    def __getitem__(self, idx): # 기본적인 구성\n",
        "        session = self.short_session_dataset[idx]\n",
        "        \"\"\" MLM 입력 \"\"\"\n",
        "        mask_ratio = 0.15\n",
        "        self.corrupt_tokens = []\n",
        "        self.output_tokens = []\n",
        "        for i, utt in enumerate(session):\n",
        "            original_token = self.tokenizer.encode(utt, add_special_tokens=False)\n",
        "\n",
        "            mask_num = int(len(original_token)*mask_ratio)\n",
        "            mask_positions = random.sample([x for x in range(len(original_token))], mask_num)\n",
        "            corrupt_token = []\n",
        "            for pos in range(len(original_token)):\n",
        "                if pos in mask_positions:\n",
        "                    corrupt_token.append(self.tokenizer.mask_token_id)\n",
        "                else:\n",
        "                    corrupt_token.append(original_token[pos])\n",
        "\n",
        "            if i == len(session)-1:\n",
        "                self.output_tokens += original_token\n",
        "                self.corrupt_tokens += corrupt_token\n",
        "            else:\n",
        "                self.output_tokens += original_token + [self.tokenizer.sep_token_id]\n",
        "                self.corrupt_tokens += corrupt_token + [self.tokenizer.sep_token_id]    \n",
        "        \n",
        "        \"\"\" label for loss \"\"\"\n",
        "        self.corrupt_mask_positions = []\n",
        "        for pos in range(len(self.corrupt_tokens)):\n",
        "            if self.corrupt_tokens[pos] == self.tokenizer.mask_token_id:\n",
        "                self.corrupt_mask_positions.append(pos)                \n",
        "                \n",
        "        \"\"\" URC 입력 \"\"\"\n",
        "        urc_tokens = []\n",
        "        context_utts = []\n",
        "        for i in range(len(session)):\n",
        "            utt = session[i]    \n",
        "            original_token = self.tokenizer.encode(utt, add_special_tokens=False)\n",
        "            if i == len(session)-1:\n",
        "                urc_tokens += [self.tokenizer.eos_token_id]\n",
        "                \"\"\" 기존 response 입력 \"\"\"\n",
        "                self.positive_tokens = [self.tokenizer.cls_token_id] + urc_tokens + original_token\n",
        "                \"\"\" random negative respons 입력 \"\"\"\n",
        "                while True:\n",
        "                    random_neg_response = random.choice(self.all_utts)\n",
        "                    if random_neg_response not in context_utts:\n",
        "                        break\n",
        "                random_neg_response_token = self.tokenizer.encode(random_neg_response, add_special_tokens=False)\n",
        "                self.random_tokens = [self.tokenizer.cls_token_id] + urc_tokens + random_neg_response_token\n",
        "                \"\"\" context negative response 입력 \"\"\"\n",
        "                context_neg_response = random.choice(context_utts)\n",
        "                context_neg_response_token = self.tokenizer.encode(context_neg_response, add_special_tokens=False)\n",
        "                self.context_neg_tokens = [self.tokenizer.cls_token_id] + urc_tokens + context_neg_response_token\n",
        "            else:\n",
        "                urc_tokens += original_token + [self.tokenizer.sep_token_id]\n",
        "            context_utts.append(utt)\n",
        "        \n",
        "        return self.corrupt_tokens, self.output_tokens, self.corrupt_mask_positions, [self.positive_tokens, self.random_tokens, self.context_neg_tokens], [0, 1, 2]\n",
        "    \n",
        "    def collate_fn(self, sessions): # 배치를 위한 구성\n",
        "        '''\n",
        "            input:\n",
        "                data: [(session1), (session2), ... ]\n",
        "            return:\n",
        "                batch_corrupt_tokens: (B, L) padded\n",
        "                batch_output_tokens: (B, L) padded\n",
        "                batch_corrupt_mask_positions: list\n",
        "                batch_urc_inputs: (B, L) padded\n",
        "                batch_urc_labels: (B)\n",
        "                batch_mlm_attentions\n",
        "                batch_urc_attentions\n",
        "\n",
        "            batch가 3\n",
        "            MLM = 3개의 입력데이터 (입력데이터별로 길이가 다름)\n",
        "            URC = 9개의 입력데이터 (context는 길이가 다름, response candidate도 길이가 다름)\n",
        "        '''\n",
        "        batch_corrupt_tokens, batch_output_tokens, batch_corrupt_mask_positions, batch_urc_inputs, batch_urc_labels = [], [], [], [], []\n",
        "        batch_mlm_attentions, batch_urc_attentions = [], []\n",
        "        # MLM, URC 입력에 대해서 가장 긴 입력 길이를 찾기\n",
        "        corrupt_max_len, urc_max_len = 0, 0\n",
        "        for session in sessions:\n",
        "            corrupt_tokens, output_tokens, corrupt_mask_positions, urc_inputs, urc_labels = session\n",
        "            if len(corrupt_tokens) > corrupt_max_len:\n",
        "                corrupt_max_len = len(corrupt_tokens)\n",
        "            positive_tokens, random_tokens, context_neg_tokens = urc_inputs\n",
        "            if max([len(positive_tokens), len(random_tokens), len(context_neg_tokens)]) > urc_max_len:\n",
        "                urc_max_len = max([len(positive_tokens), len(random_tokens), len(context_neg_tokens)])\n",
        "                \n",
        "        ## padding 토큰을 추가하는 부분\n",
        "        for session in sessions:\n",
        "            corrupt_tokens, output_tokens, corrupt_mask_positions, urc_inputs, urc_labels = session\n",
        "            \"\"\" mlm 입력 \"\"\"\n",
        "            batch_corrupt_tokens.append(corrupt_tokens + [self.tokenizer.pad_token_id for _ in range(corrupt_max_len-len(corrupt_tokens))])\n",
        "            batch_mlm_attentions.append([1 for _ in range(len(corrupt_tokens))] + [0 for _ in range(corrupt_max_len-len(corrupt_tokens))])\n",
        "            \n",
        "            \"\"\" mlm 출력 \"\"\"\n",
        "            batch_output_tokens.append(output_tokens + [self.tokenizer.pad_token_id for _ in range(corrupt_max_len-len(corrupt_tokens))])\n",
        "            \n",
        "            \"\"\" mlm 레이블 \"\"\"\n",
        "            batch_corrupt_mask_positions.append(corrupt_mask_positions)\n",
        "            \n",
        "            \"\"\" urc 입력 \"\"\"\n",
        "            # positive_tokens, random_tokens, context_neg_tokens = urc_inputs\n",
        "            for urc_input in urc_inputs:                            \n",
        "                batch_urc_inputs.append(urc_input + [self.tokenizer.pad_token_id for _ in range(urc_max_len-len(urc_input))])\n",
        "                batch_urc_attentions.append([1 for _ in range(len(urc_input))] + [0 for _ in range(urc_max_len-len(urc_input))])\n",
        "            \n",
        "            \"\"\" urc 레이블 \"\"\"\n",
        "            batch_urc_labels += urc_labels\n",
        "        return torch.tensor(batch_corrupt_tokens), torch.tensor(batch_output_tokens), batch_corrupt_mask_positions, torch.tensor(batch_urc_inputs), \\\n",
        "        torch.tensor(batch_urc_labels), torch.tensor(batch_mlm_attentions), torch.tensor(batch_urc_attentions)"
      ],
      "metadata": {
        "id": "g_PmGszrIpa4"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "data_path = './korean_smile_style_dataset/smile.csv'\n",
        "post_dataset = post_loader(data_path)\n",
        "post_dataloader = DataLoader(post_dataset, batch_size=2, shuffle=True, num_workers=4, collate_fn=post_dataset.collate_fn)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rWa2cJE-NBzu",
        "outputId": "565d42d0-a1a2-4641-eb40-10128a3913f7"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for data in post_dataloader:\n",
        "    batch_corrupt_tokens, batch_output_tokens, batch_corrupt_mask_positions, batch_urc_inputs, batch_urc_labels, batch_mlm_attentions, batch_urc_attentions = data\n",
        "    break"
      ],
      "metadata": {
        "id": "giqYxEUHPaKy"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_corrupt_tokens.shape, batch_output_tokens.shape, batch_corrupt_mask_positions, batch_urc_inputs.shape, batch_urc_labels.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8a2s9uSHQ2n4",
        "outputId": "e370f265-843f-45c1-ffdb-eda438db80cf"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([2, 50]),\n",
              " torch.Size([2, 50]),\n",
              " [[1, 14, 28, 33, 46], [4, 16, 28, 35]],\n",
              " torch.Size([6, 62]),\n",
              " torch.Size([6]))"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "post_dataset.tokenizer.decode(batch_corrupt_tokens[0,:]), post_dataset.tokenizer.decode(batch_output_tokens[0,:])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L1k8G9Q4RCBH",
        "outputId": "55a6f848-d4aa-4a55-871e-2804c7a997cb"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('영국 [MASK] 뭘 할지 벌써부터 기대되네요. <SEP> 영국 음식 [MASK] 그렇게 맛있데요. <SEP> 그런가요? 일단 먹고 싶은 [MASK]을 몇 개 정리 [MASK]뒀습니다. <SEP> 그리고 영국의 관광지는 다 보 [MASK]야죠.',\n",
              " '영국에서 뭘 할지 벌써부터 기대되네요. <SEP> 영국 음식이 그렇게 맛있데요. <SEP> 그런가요? 일단 먹고 싶은 음식을 몇 개 정리해뒀습니다. <SEP> 그리고 영국의 관광지는 다 보셔야죠.')"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "post_dataset.tokenizer.decode(batch_corrupt_tokens[0,:]), post_dataset.tokenizer.decode(batch_output_tokens[1,:])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H5uyqYHvRDPn",
        "outputId": "de3d26ef-23ef-4daa-a3c4-040090403fef"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('영국 [MASK] 뭘 할지 벌써부터 기대되네요. <SEP> 영국 음식 [MASK] 그렇게 맛있데요. <SEP> 그런가요? 일단 먹고 싶은 [MASK]을 몇 개 정리 [MASK]뒀습니다. <SEP> 그리고 영국의 관광지는 다 보 [MASK]야죠.',\n",
              " '아침을 드시나요? <SEP> 아니요, 저는 아침을 안 먹습니다. <SEP> 저는 매일 아침 시리얼 한 그릇을 먹고 나와요. <SEP> 시리얼 한 그릇을 먹으면 배가 차나요? [PAD] [PAD] [PAD] [PAD] [PAD]')"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_mlm_attentions"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "crS2bUy6REH-",
        "outputId": "1bdc4a44-c725-43c3-82ff-6e2c04b8b7ec"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1],\n",
              "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
              "         0, 0]])"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "post_dataset.tokenizer.decode(batch_urc_inputs[0]), batch_urc_labels"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R2mSKRVvRFDH",
        "outputId": "6d7a91e7-d5bf-4c3c-a446-bed3814f15a3"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('[CLS] 영국에서 뭘 할지 벌써부터 기대되네요. <SEP> 영국 음식이 그렇게 맛있데요. <SEP> 그런가요? 일단 먹고 싶은 음식을 몇 개 정리해뒀습니다. <SEP> [SEP] 그리고 영국의 관광지는 다 보셔야죠. [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]',\n",
              " tensor([0, 1, 2, 0, 1, 2]))"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 파일로 저장하기"
      ],
      "metadata": {
        "id": "92oQJuunRyhm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!touch dataset.py"
      ],
      "metadata": {
        "id": "ImHwhVFwRJHQ"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from dataset import post_loader\n",
        "from torch.utils.data import DataLoader\n",
        "data_path = './korean_smile_style_dataset/smile.csv'\n",
        "post_dataset = post_loader(data_path)\n",
        "post_dataloader = DataLoader(post_dataset, batch_size=2, shuffle=True, num_workers=4, collate_fn=post_dataset.collate_fn)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "USEbuHgXR4DP",
        "outputId": "a4589b17-1c9a-4d83-b2b9-4f23affdd382"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for data in post_dataloader:\n",
        "    batch_corrupt_tokens, batch_output_tokens, batch_corrupt_mask_positions, batch_urc_inputs, batch_urc_labels, batch_mlm_attentions, batch_urc_attentions = data\n",
        "    break"
      ],
      "metadata": {
        "id": "HiVwYiR5SGKP"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_corrupt_tokens.shape, batch_output_tokens.shape, batch_corrupt_mask_positions, batch_urc_inputs.shape, batch_urc_labels.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kVlrRCEASIov",
        "outputId": "596be556-2553-4ae2-c345-e94a1ce3fc93"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([2, 61]),\n",
              " torch.Size([2, 61]),\n",
              " [[4, 22, 35, 39, 48], [7, 14, 28, 34, 41, 53]],\n",
              " torch.Size([6, 89]),\n",
              " torch.Size([6]))"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 모델링하기"
      ],
      "metadata": {
        "id": "Eay00ZL0SVGG"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5iPDiq4oSJ35"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}